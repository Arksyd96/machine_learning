{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Machine learning**\r\n",
    "\r\n",
    "### *Introduction*\r\n",
    "- Machine learning helps to reproduce tasks that cannot be programmed by hand and taks that are made by humans. It is also used for data mining and self-customizing programs (Customizing preferences and data).\r\n",
    "- ML gives the capability to machines to learn without being explicitly programmed.\r\n",
    "- Types of ML :\r\n",
    "  - Supervised learning: We're given a dataset with labels, in other words, we already know what our output should look like. Supervised learning is categorized into :\r\n",
    "    1. Regression problems: Predicting output within a continuous domain of definition (Mapping to a continuous function).\r\n",
    "    2. Classification problems: Predicting output in a descrete domain of definition (Mapping to a descrete categories, can be seen as a step function).\r\n",
    "  - Unsupervised learning: We're given a dataset without knowing how our results should look like and don't necessarily know the effect of each variable. A solution is usually to cluster data based on relationships among the variables. With unsupervised learning, there's no feedback on the prediction results.\r\n",
    "  - Other: Reinforcement learning, recommender systems.\r\n",
    "\r\n",
    "# Linear regression :\r\n",
    "- Given a training set, our main goal is to learn a mapping function $h: x \\rightarrow y$ which can predict correctly (or approximatly) a value of $y$ given $x$ as input ($x, y \\in \\reals$).\r\n",
    "- By default, we define the hypothesis function as follow : $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x$ where $\\theta_{i}$ are parameters.\r\n",
    "- $h(x)$ is a function for univariate linear regression (with one variable as input).\r\n",
    "-  Cost function is a function that measures the loss between the output of $h(x)$ and the ground truth value $y$.\r\n",
    "- Most commonly used cost function for regression problems is the \"Mean squared error\" and is defined as follow :\r\n",
    "$$ J(\\theta_{0}, \\theta_{1}) = \\frac{1}{2m} \\sum_1^m (\\widehat{y} - y)^2 $$  \r\n",
    "\r\n",
    "- Where $m$ is the number of training examples and $\\widehat{y}$ is the predicted output. We put $\\frac{1}{2}$ on the MSE to simplify the computation of the gradient descent, when derived, it cancels the square value.\r\n",
    "\r\n",
    "#### 1. Gradient descent:\r\n",
    "- We modify values of the parameters by substracting it's gradient each time until we get a function $h$ that predicts well. In other words, finding a combination of parameters $\\theta_{0}, \\theta_{1}, ..., \\theta_{n}$ that minimizes the cost function as much as possible. In some cases we run into local minimums when dealing with complex functions, one possible solution is to restart the learning phase with another distribution of parameters.  \r\n",
    "``Repeat until convergence:``\r\n",
    "$$ \\theta_{j} := \\theta_{j} - \\eta \\times \\frac{\\partial}{\\partial \\theta_{j}}J(\\theta_{0}, \\theta_{1},...,\\theta{n}) $$  \r\n",
    "Where $\\eta$ is the learning rate. This parameter has an impact on the training speed, a substancial value means a faster learning but can sometimes cause oscillations and diverge, in the other case, if $\\eta$ is too small then gradient descent will be slow.\r\n",
    "- *Note*: All the parameters should be updated at once.\r\n",
    "- One possible solution if the cost starts growing after $k$ iterations, is to reduce the value of the learning rate $\\eta$.\r\n",
    "- If $\\eta$ is sufficiently small, the cost should decrease on every iteration, but if $\\eta$ is too small, the gradient descent will hardly converge.\r\n",
    "\r\n",
    "#### 2. Multivariate linear regression (Linear algebra):\r\n",
    "- let $n$ be the number of input features. If $n > 1$, then we're working on multivariate linear regression problem :\r\n",
    "$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n}x_{n}$\r\n",
    "- By vectorizing our hypothesis function, we'll be able to reduce the computing time and apply gradient descent on all training examples at once. This method is called '**Batch gradient descent (BGD)**' (Update is made on a whole batch of examples).  \r\n",
    "$$ \\theta = \\begin{bmatrix}\\theta_{0} \\\\\\theta_{1} \\\\... \\\\\\theta_{n} \\end{bmatrix},\r\n",
    "x = \\begin{bmatrix}x_{0}^{(1)} & x_{0}^{(2)} & ... & x_{0}^{(m)}\\\\x_{1}^{(1)} & x_{1}^{(2)} & ... & x_{1}^{(m)} \\\\. & . & . & . \\\\x_{n}^{(1)} & x_{n}^{(2)} & ... & x_{n}^{(m)} \\end{bmatrix}, \r\n",
    "h_{\\theta}(x) = \\theta^{T}x$$  \r\n",
    "\r\n",
    "- In more details, here's what the **BGD** formula looks like : $ \\theta_{j} := \\theta_{j} - \\frac{\\eta}{m} \\sum_i^m \\frac{\\partial}{\\partial \\theta_{j}}J^{(i)}(\\theta_{0}, \\theta_{1},..., \\theta_{n}) $ where $\\frac{\\partial J}{\\partial \\theta_{j}}$ formula can be found as follow :  \r\n",
    "$$\\frac{\\partial J}{\\partial \\theta_{j}} = \\frac{\\partial J}{\\partial h}\\frac{\\partial h}{\\partial \\theta_{j}} = (h_{\\theta}(x) - y)x_{j}$$\r\n",
    "$$ \\theta_{j} := \\theta_{j} - \\frac{\\eta}{m} \\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} $$\r\n",
    "\r\n",
    "#### 3. Features scaling (Mean normalization):\r\n",
    "- When dealing with multivariate regression problems, it is important to rescale all the features to the same range around 0, especially when we have different units. Variables that are measured at different scales do not contribute equally to the analysis and might end up creating a bais. A variable that ranges between 0 and 1000 will outweigh a variable that ranges between 0 and 1.\r\n",
    "- One way to rescal input features is to apply the formule :\r\n",
    "$$ x_{i} := \\frac{x_{i} - \\mu_{i}}{s_{i}} $$  \r\n",
    "Where $\\mu_{i}$ is the average value of the feature $x_{i}$ and $s_{i}$ is the standard deviation ``max - min``.\r\n",
    "\r\n",
    "#### 4. Normal equations :\r\n",
    "- Another method to minimize the function $\\partial J$ without using an iterative algorithm like the gradient descent, is to use the '**Normal equation**'. In this method we minimize the cost by resolving the problem $\\frac{\\partial J}{\\partial \\theta} = 0$ and by simplyfing this equation, we obtain the normal equation formula:\r\n",
    "$$\\theta = (X^TX)^{-1}X^Ty$$ \r\n",
    "- I explain in more details the demonstration of this function [here](https://github.com/Arksyd96/machine_learning/blob/main/normal_equation_demonstration.ipynb) ([NBviewer version](https://nbviewer.jupyter.org/github/Arksyd96/machine_learning/blob/main/normal_equation_demonstration.ipynb)).\r\n",
    "- The normal equation has some advantages and disadvantages over the default method which is gradient descent. Here are some points (From Andrew Ng's course):\r\n",
    "  - **Gradient descent**:\r\n",
    "    - Pros:\r\n",
    "      - Complexity $O(knÂ²)$.\r\n",
    "      - Works well when the number of features is large.\r\n",
    "    - Cons:\r\n",
    "      - Features scaling is necessary.\r\n",
    "      - Needs many iterations.\r\n",
    "      - Needs to define a learning rate $\\eta$.\r\n",
    "  - **Normal equation**:\r\n",
    "    - Pros:\r\n",
    "      - No iteration.\r\n",
    "      - No need to a learning rate.      \r\n",
    "    - Cost:\r\n",
    "      - Computing the inverse of $X^TX$ has a complexity of $O(n^3)$.\r\n",
    "      - Slow when dealing with a lot of features\r\n",
    "- *Note:* Features scaling is not necessary when working with normal equation, keeping the features as they are won't affect the results.\r\n",
    "- It is recommended to use **Normal equation** when the number of features $n$ does not exceed $10^{5 to 6}$, otherwise, gradient descent is better. \r\n",
    "- *Note:* In some cases, the term $X^TX$ is noninvertible. This can happen if:\r\n",
    "  - There are redundant or/and linearly dependent features.\r\n",
    "  - Too many features $n > m$.\r\n",
    "\r\n",
    "# Polynomial regression:\r\n",
    "- Sometimes, th repartition of our training data forms a non-linear curve, and our hypothesis function cannot fit all these data. In order to deal with non-linear problems, we have to use polynomial regression.\r\n",
    "- The idea behind polynomial regression is to compose our input features with non-linear functions then create new additionnal features based on those compositions. Here are some examples:\r\n",
    "  - Quadratic function: $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{1}^2$\r\n",
    "  - Cubic function: $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{1}^2 + \\theta_{3}x_{1}^3$\r\n",
    "  - Root squared function: $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}\\sqrt{x_{1}}$\r\n",
    "- One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important. Do not forget it to normalize your inputs.\r\n",
    "\r\n",
    "# Classification:\r\n",
    "- Given a training set, our goal is to predict in to which class a training example belongs, unlike the logistic regression hypothesis function, in classification, we predict discrete values $y \\in \\{0, 1, ..., n_{class}\\}$.\r\n",
    "- When the number of output classes $n_{class}$ is equal to $2$, we call it a binary classification problem and outputs are either positive ($1$) or negative ($0$). \r\n",
    "- One method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. However, this method doesn't work well because classification is not actually a linear function (By Andrew Ng). On possible alternative is to use **Logistic regression**.\r\n",
    "\r\n",
    "#### 1. Logistic regression:\r\n",
    "- **Logistic regression** is the most commonly used technique for binary classification. Our hypothesis function needs to be modified because the default outputs values greater than 1 and lower than 0. In order to obtain $\\hat{y} \\in \\{0, 1\\}$ we will combine our hypothesis function with a logistic function to satisfy $0 \\leq h_{\\theta}(x) \\leq 1$. The output will be then interpreted as a probabilty.\r\n",
    "$$ h_{\\theta}(x) = P(y = 1|x;\\theta) \\in [0, 1] $$\r\n",
    "$$  h_{\\theta}(x) = \\sigma(\\theta^Tx), \\;\\; where \\;\\; \\sigma(x) = \\frac{1}{1 + e^{-x}} $$\r\n",
    "- The function $\\sigma$ is also called sigmoid function. This function maps any real number to the interval $[0, 1]$ which makes it useful for binary classification.\r\n",
    "- The sigmoid is a non-linear function, combined with $h_{\\theta}(x)$, it allows us solve complex problems that require non-linear functions.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "##### Decision boundary:\r\n",
    "- Decision boundary (or decision surface) is a function that delimits the region of each class in the data space. If the decision surface is a hyperplane, then the classification problem is linear, and the classes are linearly separable ([Wikipedia](https://en.wikipedia.org/wiki/Linear_separability)).\r\n",
    "- In order to find the decision boundry function of a binary classification problem:\r\n",
    "$$ given \\;\\; h_{\\theta}(x) = \\sigma(z) \\;\\; where \\;\\; z = \\theta^Tx $$\r\n",
    "$$ y = 1 \\;\\; if \\;\\; h_{\\theta}(x) \\geq 0.5 \\implies z \\geq 0 $$\r\n",
    "$$ y = 0 \\;\\; if \\;\\; h_{\\theta}(x) < 0.5 \\implies z < 0 $$\r\n",
    "$$ \\theta^Tx = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n = 0 $$\r\n",
    "\r\n",
    "- Unlike regression problems, we cannot use the 'Mean squared error' cost function because when combined with a sigmoid, the output function will be non-convex and thus, will contain many local optima. Instead we use cross-entropy cost function which looks like this:\r\n",
    "$$ J(\\theta) = \\begin{cases}y=1 & -log(h_{\\theta}(x))\\\\y=0 & -log(1 - h_{\\theta}(x))\\end{cases}  $$\r\n",
    "- If the model makes a mistake (predicts $1$ when $y = 0$ or predict $0$ when $y = 1$), the value of the cost will converge to $\\infty$.\r\n",
    "- If the model makes a good prediction, the value of the cost will converge to $0$.\r\n",
    "- Writting the function this way, when combined with the sigmoid will output a convex function (A function with the form of a bowl, with only 1 optimum)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}